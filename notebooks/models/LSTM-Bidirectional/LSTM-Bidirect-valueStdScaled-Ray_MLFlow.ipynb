{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd0468-6aec-44b6-b25c-41f4e33d2161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "os.environ[\"RAY_IGNORE_UNHANDLED_ERRORS\"] = \"1\"\n",
    "os.environ[\"TUNE_DISABLE_STRICT_METRIC_CHECKING\"] = \"1\"\n",
    "os.environ[\"RAY_memory_monitor_refresh_ms\"] = \"0\" # do not kill raylet if low on memmory\n",
    "os.environ[\"RAY_TASK_MAX_RETRIES\"] = \"2\"\n",
    "\n",
    "os.environ[\"TUNE_PLACEMENT_GROUP_AUTO_DISABLED\"] = \"1\" #neded only when running local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9295d-1649-44d5-85ef-1d53b8bd3b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, Flatten, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c4d6c1-5e6c-4cfe-9a01-f1c81e433c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import train, tune, air\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a90ec4-dca9-446c-bba8-757be0778772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d263b45-a0c9-4f3c-99f6-377b799629bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from ray.air.integrations.mlflow import setup_mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab2a1e-8bf8-41ac-b660-ce8c3fc0a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad016c2b-308b-4062-9b6d-2fe45b53436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTypeName = \"LSTM_Bi_valueStdScaled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ead78-6a6e-405c-b8b3-64e5622226c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataColumnName = 'valueStdScaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d1e63-efa7-4b42-86ab-749f78229cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_URI='http://localhost:8080/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4822286-4fdd-400c-9f21-a031062e5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space={\n",
    "    \"n_epochs\": tune.choice([200]),\n",
    "    \"n_layers\": tune.choice([1, 3, 5, 10]),\n",
    "    \"n_dense_layers\": tune.choice([1, 3, 5]), \n",
    "    \"learning_rate\": tune.choice([0.003, 0.001]),\n",
    "    \"activation\": tune.choice(['tanh', 'relu']), \n",
    "    \"n_neurons\": tune.choice([32, 64, 96, 128, 256]),\n",
    "    \"T\": tune.choice([5, 10, 15, 20]),\n",
    "    \"dense_dp\": tune.choice([0.2, 0.3, 0.4]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e90dc-2eb7-430d-b456-e34e7c1db2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../lib/utils_anomaly_detection.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94211d75-d898-4b48-bf64-bdbca6b7aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b17d5c-4253-4bf5-b0a0-7544492d4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "data = pd.read_csv('../../data/rq_1-3_train_test/2024-01-15_10-51-45__2024-01-15_14-26-45_load-gen-msg-w-spikes-10s-rate.csv', \n",
    "                   index_col=['EventDateTime'], parse_dates=['EventDateTime'])\n",
    "dataLatency = pd.read_csv('../../data/rq_1-3_train_test/2024-01-15_10-51-45__2024-01-15_14-26-45_load-gen-avg-latency-10s-rate.csv', \n",
    "                          index_col='EventDateTime', parse_dates=['EventDateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a188d-4180-48e8-8da1-982a5dcb5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../lib/prepareDataSet.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6173b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
    "from keras.models import load_model, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827103c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " This function uses one Tensor formatted input from the X_test dataset in order to predict ahead by a number\n",
    " of given steps. Then it readjusts by using another true value from X_test (as the nex index) before starting\n",
    " a new prediction cycle\n",
    "\"\"\"\n",
    "def generate_nsteps_forecast(x_test, nn_model, pred_ahead):\n",
    "    max_len = x_test.shape[0]\n",
    "    y_pred = []\n",
    "    last_x = x_test[0]\n",
    "    index = 0\n",
    "    while len(y_pred) < max_len:\n",
    "        sequence = 0\n",
    "        while sequence < pred_ahead:\n",
    "            try:\n",
    "                x_crt_input = last_x.reshape(1, -1, 1)\n",
    "                p_vector = nn_model.predict(x_crt_input, verbose=0)\n",
    "                p = p_vector[0,0] # 1x1 array -> scalar\n",
    "            except:\n",
    "                print(f'Prediction error for x={x_crt_input} at sequence={sequence} for start index={index} when pred_ahead={pred_ahead}')\n",
    "                print(f'Model config was:{nn_model.get_config()}')\n",
    "                p = 0\n",
    "                \n",
    "            # update the predictions list\n",
    "            y_pred.append(p)\n",
    "\n",
    "            # make the new input\n",
    "            last_x = np.roll(last_x, -1)\n",
    "            last_x[-1] = p\n",
    "            \n",
    "            # increase index for the next run\n",
    "            sequence += 1\n",
    "\n",
    "        index += sequence\n",
    "        if index < max_len:\n",
    "            last_x = x_test[index]\n",
    "            #print(f\"Arrived at index = {index} of {max_len} with value X={last_x}\")\n",
    "    \n",
    "    if len(y_pred) > max_len:\n",
    "        # predicted too much, cutoff the tail\n",
    "        y_pred = y_pred[0:max_len]\n",
    "        \n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634208ab-b70c-4ef5-b984-fe0a94c29ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(config):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(config[\"T\"],1)))\n",
    "    for i in range(config[\"n_layers\"] - 1):\n",
    "        model.add(Bidirectional(LSTM(config[\"n_neurons\"], activation=config['activation'],return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(config[\"n_neurons\"], activation=config['activation'],return_sequences=False)))\n",
    "\n",
    "    for i in range(config[\"n_dense_layers\"]-1):\n",
    "        model.add(Dense(config[\"n_neurons\"], activation=\"relu\"))\n",
    "        model.add(Dropout(rate=config[\"dense_dp\"]))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae32852-2dda-40c0-8964-70071a3c63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    \n",
    "\n",
    "    n_neurons = config['n_neurons']\n",
    "    n_epochs = config['n_epochs']\n",
    "    learning_rate = config['learning_rate']\n",
    "    T = config['T']\n",
    "\n",
    "    model_exp =  f'{modelTypeName}'\n",
    "    UUID = uuid.uuid4().hex\n",
    "\n",
    "    mlflow_exp_name = f'{modelTypeName}-{UUID}-T_{T}-LY_{config[\"n_layers\"]}-DLY_{config[\"n_dense_layers\"]}-NN_{n_neurons}'\n",
    "\n",
    "    import mlflow\n",
    "\n",
    "    mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "    mlflow.set_registry_uri(MLFLOW_URI)\n",
    "    \n",
    "    nn_model = create_model(config)\n",
    "    nn_model.compile(loss='mse', metrics='mse', optimizer=Adam(learning_rate=config[\"learning_rate\"]))\n",
    "    \n",
    "    X_train, Y_train, X_test, Y_test = prepare_dataset(dataFrame[dataColumnName], T)\n",
    "    \n",
    "    model_name = modelTypeName + \"-T_\" + str(T) + \"-LY_\" + str(config['n_layers']) + \"-DLY_\" + str(config['n_dense_layers']) +\\\n",
    "                 \"-NN_\" + str(n_neurons) + \"-LR_\" + str(learning_rate) + \"-epochs_\" + str(n_epochs) +\"-\" + UUID + \".keras\"\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=5)\n",
    "    mc = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True)    \n",
    "    \n",
    "    train_results = nn_model.fit(X_train, Y_train, \n",
    "                                 epochs=config['n_epochs'], \n",
    "                                 validation_data=(X_test, Y_test), \n",
    "                                 #callbacks=[ReportCheckpointCallback(metrics={\"mse\": \"mse\"}, checkpoint_on=\"train_end\")],\n",
    "                                 callbacks=[es, mc],\n",
    "                                 verbose = 0\n",
    "                                )\n",
    "    \n",
    "    #evaluate and print results\n",
    "    try:\n",
    "        saved_model = load_model(model_name)\n",
    "    except:\n",
    "        saved_model = nn_model\n",
    "        save_model(nn_model, model_name)\n",
    "\n",
    "    y_predict = saved_model.predict(X_test, verbose=0)\n",
    "    errors_ae = calculate_absolute_prediction_errors(Y_test, y_predict)\n",
    "    anomalies_ae = calculate_3sigma_anomalies(errors_ae)\n",
    "    errors_se = calculate_squared_prediction_errors(Y_test, y_predict)\n",
    "    anomalies_se = calculate_3sigma_anomalies(errors_se)\n",
    "\n",
    "    anomalies_3sigma_Y_test = calculate_3sigma_anomalies(Y_test)\n",
    "    anomalies_3sigma_y_predict = calculate_3sigma_anomalies(y_predict)\n",
    "    \n",
    "    anomalies_Y_test, z_scores_Y_test = calculate_zscore_anomalies(Y_test)\n",
    "    anomalies_y_predict, z_scores_y_predict = calculate_zscore_anomalies(y_predict)\n",
    "    anomalies_errors_ae, z_scores_errors_ae = calculate_zscore_anomalies(errors_ae)\n",
    "    anomalies_errors_se, z_scores_errors_se = calculate_zscore_anomalies(errors_se)\n",
    "    \n",
    "    anomalies_Y_test_mod, z_scores_Y_test_mod = calculate_modified_zscore_anomalies(Y_test)\n",
    "    anomalies_y_predict_mod, z_scores_y_predict_mod = calculate_modified_zscore_anomalies(y_predict)\n",
    "    anomalies_errors_ae_mod, z_scores_errors_ae_mod = calculate_modified_zscore_anomalies(errors_ae)\n",
    "    anomalies_errors_se_mod, z_scores_errors_se_mod = calculate_modified_zscore_anomalies(errors_se)\n",
    "    \n",
    "    try:\n",
    "        r2 = r2_score(Y_test, y_predict)\n",
    "    except:\n",
    "        r2 = 110\n",
    "    if np.isnan(r2):\n",
    "        r2 = 110\n",
    "\n",
    "    try:\n",
    "        mae = mean_absolute_error(Y_test, y_predict)\n",
    "    except:\n",
    "        mae = 100\n",
    "    if np.isnan(mae):\n",
    "        mae = 100\n",
    "\n",
    "    try:\n",
    "        mape = mean_absolute_percentage_error(Y_test, y_predict)\n",
    "    except:\n",
    "        mape = 100\n",
    "    if np.isnan(mape):\n",
    "        mape = 100\n",
    "\n",
    "    try:\n",
    "        mse = mean_squared_error(Y_test, y_predict)\n",
    "    except:\n",
    "        mse = 100\n",
    "    if np.isnan(mse):\n",
    "        mse = 100\n",
    "    \n",
    "    try:\n",
    "        pcc = np.corrcoef(Y_test, y_predict.flatten())[0,1]\n",
    "    except:\n",
    "        pcc = 100\n",
    "    if np.isnan(pcc):\n",
    "        pcc = 100\n",
    "\n",
    "    experiment_id = mlflow.create_experiment(mlflow_exp_name)\n",
    "    with mlflow.start_run(run_name=mlflow_exp_name, experiment_id=experiment_id) as mlflowrun:\n",
    "        run_id = mlflowrun.info.run_id\n",
    "\n",
    "        fig = plt.figure(figsize=(20,15))\n",
    "        plt.title(\"Anomalies Y_test\")\n",
    "        plt.plot(Y_test,label=\"Original Data\", alpha=0.6, c='gray')\n",
    "        plt.scatter(np.where(anomalies_Y_test==True)[0], Y_test[np.where(anomalies_Y_test==True)], \n",
    "                    alpha=0.8, color='green', s=250, label=\"Z-Score Anomalies\")\n",
    "        plt.scatter(np.where(anomalies_3sigma_Y_test==True)[0], Y_test[np.where(anomalies_3sigma_Y_test==True)], \n",
    "                    alpha=0.8, color='red', s=150, label=\"3-Sigma Anomalies\")\n",
    "        plt.scatter(np.where(anomalies_Y_test_mod==True)[0], Y_test[np.where(anomalies_Y_test_mod==True)], \n",
    "                    alpha=0.8, color='blue', s=100, label=\"Modified Z-Score Anomalies\")    \n",
    "        plt.legend()\n",
    "        figName = f\"Y_test_anomalies-T_{T}.png\"\n",
    "        mlflow.log_figure(fig, figName)\n",
    "        #plt.savefig(figName, transparent=False)\n",
    "        fig.clf()\n",
    "        plt.close()\n",
    "    \n",
    "        fig = plt.figure(figsize=(20,15))\n",
    "        plt.title(\"Predict Anomalies T=\" + str(T) + \" with predict 1 on \"+ str(model_exp) +\": NN=\" + str(n_neurons) + \" epochs=\" + str(n_epochs) +\n",
    "                  \" lr=\" + str(learning_rate))\n",
    "        plt.plot(y_predict,label=\"Predict 1-step Forecast\", alpha=0.6, c='red', linewidth=3)\n",
    "        plt.plot(Y_test,label=\"Original Data\", alpha=0.6, c='black')\n",
    "        plt.scatter(np.where(anomalies_ae==True), y_predict[np.where(anomalies_ae==True)], \n",
    "                    alpha=0.8, color='green', s=350, label=\"3-Sigma Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_se==True), y_predict[np.where(anomalies_se==True)], \n",
    "                    alpha=0.8, color='magenta', s=300, label = \"3-Sigma Anomalies SE\")\n",
    "        plt.scatter(np.where(anomalies_errors_ae==True), y_predict[np.where(anomalies_errors_ae==True)], \n",
    "                    alpha=0.8, color='blue', s=250, label = \"Z-score Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_errors_se==True), y_predict[np.where(anomalies_errors_se==True)], \n",
    "                    alpha=0.8, color='cyan', s=200, label = \"Z-score Anomalies SE\")\n",
    "        plt.scatter(np.where(anomalies_errors_ae_mod==True), y_predict[np.where(anomalies_errors_ae_mod==True)], \n",
    "                    alpha=0.8, color='lightgreen', s=150, label = \"Modified Z-score Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_errors_se_mod==True), y_predict[np.where(anomalies_errors_se_mod==True)], \n",
    "                    alpha=0.8, color='orange', s=50, label = \"Modified Z-score Anomalies SE\")    \n",
    "        plt.legend()    \n",
    "        figName = f\"Y_predict-1-step-anomalies-T_{T}.png\"\n",
    "        mlflow.log_figure(fig, figName)\n",
    "        #plt.savefig(figName, transparent=False)\n",
    "        fig.clf()\n",
    "        plt.close()\n",
    "        \n",
    "        try:\n",
    "            signature = infer_signature(X_test, y_predict)\n",
    "    \n",
    "            mlflow.tensorflow.log_model(nn_model, model_name, \n",
    "                                            signature = signature,\n",
    "                                            #input_example=X_train[0].reshape(1, -1, 1), \n",
    "                                            registered_model_name = model_name)\n",
    "        except:\n",
    "            print(f'Ray-MLFlow: Could not save model {model_name}')\n",
    "            \n",
    "        try:\n",
    "            mlflow.log_param(\"n_layer_size\", n_neurons)\n",
    "            mlflow.log_param(\"n_layers\", config['n_layers'])\n",
    "            mlflow.log_param(\"n_dense_layers\", config['n_dense_layers'])\n",
    "            mlflow.log_param(\"activation_fn\", config['activation'])\n",
    "            mlflow.log_param(\"epochs\", n_epochs)\n",
    "            mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "            mlflow.log_param(\"optimizer\", \"adam\")\n",
    "            mlflow.log_param(\"time_window\", config['T'])\n",
    "            mlflow.log_param(\"dense_dp\", config['dense_dp'])\n",
    "            mlflow.log_param(\"model_exp\", model_exp)\n",
    "            \n",
    "            mlflow.log_metric(\"mae\", mae)\n",
    "            mlflow.log_metric(\"mse\", mse)\n",
    "            mlflow.log_metric(\"mape\", mape)\n",
    "            mlflow.log_metric(\"r2_score\", r2)\n",
    "            mlflow.log_metric(\"pearson_corr_coef\", pcc)\n",
    "            \n",
    "        except:\n",
    "            exception_param_metric_dict = {}\n",
    "            log_metric_dict = {\n",
    "                'r2_score': r2,\n",
    "                'mae': mae,\n",
    "                'mape': mape,\n",
    "                'mse': mse,\n",
    "                'pcc': pcc\n",
    "            }        \n",
    "            log_param_dict = {\n",
    "                \"n_layer_size\": n_neurons,\n",
    "                \"n_layers\": config['n_layers'],\n",
    "                \"n_dense_layers\": config['n_dense_layers'],\n",
    "                \"activation_fn\": config['activation'],\n",
    "                \"epochs\": n_epochs,\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"time_window\": config['T'],\n",
    "                \"dense_dp\": config['dense_dp'],\n",
    "                \"model_exp\": model_exp            \n",
    "            }\n",
    "            exception_param_metric_dict['log_param_dict'] = log_param_dict\n",
    "            exception_param_metric_dict['log_metric_dict'] = log_metric_dict\n",
    "            mlflow.log_dict(exception_param_metric_dict, \"exception_param_metric_dict.json\")\n",
    "\n",
    "    #train.report({\"\"mse\":mse, \"mae\":mae, \"mape\":mape, \"r2\":r2}) # for Ray>=2.7\n",
    "    \n",
    "    air.session.report({\"mse\":mse, \"mae\":mae, \"mape\":mape, \"r2\":r2, \"mlflow_exp\":mlflow_exp_name, \"model_name\":model_name, \"T\":T, \"run_id\":run_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b4d544-77f4-457f-a579-0db09ea9f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(num_training_iterations, num_samples):\n",
    "    sched = AsyncHyperBandScheduler(\n",
    "        time_attr=\"training_iteration\", max_t=10, grace_period=5\n",
    "    )\n",
    "    \n",
    "    #we have a cluster of 10 worker nodes with requests 1 CPU and limits 2 CPU settings for the pod\n",
    "    resource_group = tune.PlacementGroupFactory([{'CPU': 1.0}] * 2) \n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_model, resources=resource_group),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"mse\",\n",
    "            mode=\"min\",\n",
    "            scheduler=sched,\n",
    "            num_samples=num_samples,\n",
    "            max_concurrent_trials=10,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=modelTypeName,\n",
    "            verbose = 1,\n",
    "            stop={\"training_iteration\": num_training_iterations},\n",
    "        ),\n",
    "        param_space=param_space\n",
    "    )\n",
    "    \n",
    "    results = tuner.fit()\n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e55b9-8e9d-4a2b-9db2-1cdba6e00b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def run_n_step_evaluation(model_name, run_id, T, predict_ahead):\n",
    "    import mlflow\n",
    "\n",
    "    mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "    mlflow.set_registry_uri(MLFLOW_URI)\n",
    "\n",
    "    model = mlflow.tensorflow.load_model(f'models:/{model_name}/1')\n",
    "\n",
    "    params = mlflow.get_run(run_id).to_dictionary()['data']['params']\n",
    "    n_neurons = params['n_layer_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "    n_epochs = params['epochs']\n",
    "    model_exp = params['model_exp']\n",
    "    \n",
    "    n_step_metrics = {}\n",
    "    \n",
    "    X_train, Y_train, X_test, Y_test = prepare_dataset(dataFrame[dataColumnName], T)\n",
    "    \n",
    "    y_predict = model.predict(X_test, verbose=0)\n",
    "    y_pred_nsteps = generate_nsteps_forecast(X_test, model, predict_ahead)\n",
    "    \n",
    "    errors_ae2 = calculate_absolute_prediction_errors(Y_test, y_pred_nsteps)\n",
    "    anomalies_ae2 = calculate_3sigma_anomalies(errors_ae2)        \n",
    "    errors_se2 = calculate_squared_prediction_errors(Y_test, y_pred_nsteps)\n",
    "    anomalies_se2 = calculate_3sigma_anomalies(errors_se2)\n",
    "    anomalies_y_pred_nsteps_mod, z_scores_y_pred_nsteps_mod = calculate_modified_zscore_anomalies(y_pred_nsteps)\n",
    "    anomalies_errors_ae2_mod, z_scores_errors_ae2_mod = calculate_modified_zscore_anomalies(errors_ae2)\n",
    "    anomalies_errors_se2_mod, z_scores_errors_se2_mod = calculate_modified_zscore_anomalies(errors_se2)\n",
    "\n",
    "    try:\n",
    "        r2_nStep = r2_score(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        r2_nStep = 100\n",
    "\n",
    "    try:\n",
    "        mae_nStep = mean_absolute_error(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        mae_nStep = 100\n",
    "\n",
    "    try:\n",
    "        mape_nStep = mean_absolute_percentage_error(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        mape_nStep = 100\n",
    "\n",
    "    try:\n",
    "        mse_nStep = mean_squared_error(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        mse_nStep = 100\n",
    "\n",
    "    try:\n",
    "        pcc_nStep = np.corrcoef(Y_test, y_pred_nsteps.flatten())[0,1]\n",
    "    except:\n",
    "        pcc_nStep = 100\n",
    "\n",
    "    crt_step = f'predict_ahead_{predict_ahead}'\n",
    "    n_step_metrics[crt_step] = {\n",
    "                                    'r2_nStep': r2_nStep,\n",
    "                                    'mae_nStep': mae_nStep,\n",
    "                                    'mape_nStep': mape_nStep,\n",
    "                                    'mse_nStep': mse_nStep,\n",
    "                                    'pcc_nStep': pcc_nStep\n",
    "                                   }\n",
    "    anomalies_3sigma_y_pred_nsteps = calculate_3sigma_anomalies(y_pred_nsteps)\n",
    "    anomalies_y_pred_nsteps, z_scores_y_pred_nsteps = calculate_zscore_anomalies(y_pred_nsteps)\n",
    "    anomalies_errors_ae2, z_scores_errors_ae2 = calculate_zscore_anomalies(errors_ae2)\n",
    "    anomalies_errors_se2, z_scores_errors_se2 = calculate_zscore_anomalies(errors_se2)\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id, nested=True):\n",
    "        \n",
    "        fig = plt.figure(figsize=(20,15))\n",
    "        plt.title(\"Compare forecasts T=\" + str(T) + \" predict_ahead=\" + str(predict_ahead) + \" with predict 1\" + \n",
    "                 \" for LSTM \"+ modelTypeName +\": NN=\" + str(n_neurons) + \" LR= \" + str(learning_rate) + \" epochs=\" + str(n_epochs))\n",
    "        plt.plot(Y_test,label=\"Original Data\", alpha=0.6, c='red',linewidth=2)\n",
    "        plt.plot(y_predict,label=\"Predicted Data 1-step\", alpha=0.6, c='black', linewidth=2)\n",
    "        plt.plot(y_pred_nsteps,label=\"Predicted Data \" + str(predict_ahead) + \"-steps\", alpha=0.6, c='blue', linewidth=2)\n",
    "        plt.legend()\n",
    "        figName = f\"compare-forecasts-1_{predict_ahead}.png\"\n",
    "        mlflow.log_figure(fig, figName)\n",
    "        #plt.savefig(figName, transparent=False)\n",
    "        fig.clf()\n",
    "        plt.close()\n",
    "        \n",
    "        fig = plt.figure(figsize=(20,15))        \n",
    "        plt.title(\"Predict Anomalies T=\" + str(T) + \" with predict \" + str(predict_ahead) + \" on \" + str(model_exp) + \": NN=\" \n",
    "                  + str(n_neurons) + \" epochs=\" + str(n_epochs) + \" lr=\" + str(learning_rate))\n",
    "        plt.plot(y_pred_nsteps,label=\"Predict \" + str(predict_ahead) + \"-step Forecast\", alpha=0.6, c='red', linewidth=3)\n",
    "        plt.plot(Y_test,label=\"Original Data\", alpha=0.6, c='black')\n",
    "        plt.scatter(np.where(anomalies_ae2==True), y_pred_nsteps[np.where(anomalies_ae2==True)], \n",
    "                    alpha=0.8, color='green', s=350, label=\"Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_se2==True), y_pred_nsteps[np.where(anomalies_se2==True)], \n",
    "                    alpha=0.8, color='magenta', s=300, label = \"Anomalies SE\")\n",
    "        plt.scatter(np.where(anomalies_errors_ae2==True), y_pred_nsteps[np.where(anomalies_errors_ae2==True)], \n",
    "                    alpha=0.8, color='blue', s=250, label = \"Z-score Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_errors_se2==True), y_pred_nsteps[np.where(anomalies_errors_se2==True)], \n",
    "                    alpha=0.8, color='cyan', s=200, label = \"Z-score Anomalies SE\")\n",
    "        plt.scatter(np.where(anomalies_errors_ae2_mod==True), y_pred_nsteps[np.where(anomalies_errors_ae2_mod==True)], \n",
    "                    alpha=0.8, color='lime', s=150, label = \"Modified Z-score Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_errors_se2_mod==True), y_pred_nsteps[np.where(anomalies_errors_se2_mod==True)], \n",
    "                    alpha=0.8, color='orange', s=50, label = \"Modified Z-score Anomalies SE\")        \n",
    "        plt.legend();    \n",
    "        figName = f\"Y-predict-anomalies-step-{predict_ahead}-with-T_{T}.png\"\n",
    "        mlflow.log_figure(fig, figName)\n",
    "        #plt.savefig(figName, transparent=False)\n",
    "        fig.clf()\n",
    "        plt.close()\n",
    "\n",
    "        fname = f'{predict_ahead}-step-metric.json'\n",
    "        mlflow.log_dict(n_step_metrics, fname)\n",
    "        \n",
    "    return n_step_metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71acccd1-bb3d-4a44-8e3b-6076d2b4e51a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b6c961-0a45-499e-8246-3ac8e2cc83ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lstm = tune_model(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb745e82-4ebb-40ed-84fd-1df14fc2cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lstm.get_best_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda6bfd-bfb2-4bd3-86b8-2df6ebb0fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_n_step_predict = {}\n",
    "for result in results_lstm:\n",
    "    try:\n",
    "        model_name = result.metrics['model_name']\n",
    "        T = result.metrics['T']\n",
    "        run_id = result.metrics['run_id']\n",
    "        for predict_ahead in [5, 10, 15, 30, 60, 90, 120]: \n",
    "            res = run_n_step_evaluation.remote(model_name, run_id, T, predict_ahead)\n",
    "            tag = f'runID_{run_id}-model_{model_name}'\n",
    "            results_n_step_predict[tag] = res\n",
    "            print(f'Scheduled job for T:{T}, predict_ahead: {predict_ahead}, model_name:{model_name}, run_id:{run_id}')    \n",
    "    except:\n",
    "        print(f'ERROR scheduling job for T:{T}, predict_ahead: {predict_ahead}, model_name:{model_name}, run_id:{run_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb6f34-c6cb-41de-9f04-cab69d5fdc11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex_n_step = {}\n",
    "for item in results_n_step_predict.keys():\n",
    "    try:\n",
    "        res = ray.get(results_n_step_predict[item])\n",
    "    except:\n",
    "        print(f'Error getting results for key:{item}')\n",
    "        res = None\n",
    "        \n",
    "    ex_n_step[item]=res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1feed-4cf1-404f-b3f8-8d952d643a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ex_n_step.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcacf9d-2008-477d-a887-7d38290cec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_n_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff61e3-8f4c-43e4-866c-24d6862940dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce80a94d-4a12-434f-822d-832a8eb9ad55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-Py310",
   "language": "python",
   "name": "tf-python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
