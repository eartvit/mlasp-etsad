# ETSAD - Enhanced Time Series based Anomaly Detection in Load Test Results
This repository is the ETSAD paper experiments verification repository

*Note: The paper is not yet published, however it is pending review for being accepted for publication. As soon as that process completes, publication details shall be added here.*

In order to execute the below guide, access to a Red Hat OpenShift environment is required. If you don't have one, you can start a trial by creating an account at [RedHat Cloud website](https://cloud.redhat.com). Alternatively, it is also possible to execute the guide on a local (reduced version) of the platform, typically used for development purposes. Once you registered on the [RedHat Cloud website](https://cloud.redhat.com), you can obtain your version of the local Red Hat Openshift by downloading the installer from the [Console](https://console.redhat.com/openshift/create/local).

## Foreword
This repository contains the following:
* A quick guide for how to configure a Red Hat Openshift deployment to:
  * Set up an environment for creating and collecting data required by the ETSAD experiments
  * Set up an environment to execute the Machine Learning experiments (training and verfication)
* ETSAD research question related information:
  * Example data used as input to train and verify the ML models
  * The ML models used to test the research questions
  * The summary of the results for the three research questions

## What is Red Hat OpenShift

[Red Hat OpenShift Container Platform](https://www.redhat.com/en/technologies/cloud-computing/openshift/container-platform) (RHOCP) is a leading enterprise Kubernetes platform that enables a cloud-like experience everywhere it's deployed. Whether itâ€™s in the cloud, on-premise or at the edge, Red Hat OpenShift gives you the ability to choose where you build, deploy, and run applications through a consistent experience (Source: [RedHat](https://www.redhat.com/en/technologies/cloud-computing/openshift)).

In other words, Red Hat OpenShift Container Platform is a private Platform as a Service (PaaS) for enterprises that run OpenShift on public clouds or on-premises infrastructure. The OpenShift platform is a consistent hybrid cloud foundation for building and scaling containerized applications. In other words, it is an open-source container orchestration platform for enterprises. It includes several container technologies, primarily the OpenShift container orchestration software, which is based on the OKD open-source project. Red Hat OpenShift combines Kubernetes components with security features and productivity necessary for large enterprises and is especially useful in hybrid cloud scenarios.

Red Hat OpenShift uses operators. [Operators](https://docs.openshift.com/container-platform/4.11/operators/understanding/olm-what-operators-are.html) are pieces of software that ease the operational complexity of running another piece of software.

Throughout this guide we shall use several operators for different purposes.
* Red Hat OpenShift Data Foundation - we shall only use the Multicloud Gateway deployment option as we only need S3 compatible object bucket store
* Red Hat OpenShift AI -(RHOAI) to run the ML experiments.
* KubeRay - supporting operator for RHOAI for running parallelized ML distributed experiments (alternative to CodeFlare operator).
* MLFlow - for storing the ML experiment results.
* CrunchyDB PostgreSQL operator - support for MLFlow (required to store experiment metadata information and other MLFlow related metadata).
* Tekton -  for running automated pipeline workloads (in our case for syntetic data generation for the ML experiments).
* Prometheus - for collecting metrics required for ML experiments.
* Grafana - for visualizing metrics. This operator is optional since data visualization may be created also inside RHOAI using various Python libraries.

More details about the operators shall be provided as needed in the next sections.

*Note: This guide assumes RHOCP version 4.13.X is used.*

## Red Hat OpenShift setup and configuration for ETSAD experiments
The RHOCP platform comes with a default user with administrative privileges, kubeadmin. This user is not intended to be used on a day to daybasis and is in general used for initial setup and recovery. The kubeadmin password is generated by the installer at the end of the installation process. Use this password to login to the platform and add an OAuth provider with some users. The simplest way to do this is to setup `htpasswd` provider.

Depending on their purpose and use, the operators shall be deployed either globally or within a specific namespace, called `demo`. This `demo` namespace is the dedicated location where the synthetic data generation takes place. 

To start with the setup we shall install one by one the global operators:
* Install Red Hat OpenShift Pipelines operator. This shall provide tekton pipelines inside RHOCP.
* Install Red Hat OpenShift Data Foundation. This operator actually installs inside a dedicated workspace (reserved for it). After the installation we need to create an instance for the operator. Since we are only interested in the object bucket store, we need to select the MultiObject Gateway option when instantiating the operator.
* Install the CruncyDB PostgreSQL community operator. The PostgreSQL and Data Foundation instance shall be used by the MLFlow instance deployment to store metadata and artifacts information respectively.
* Install the MLFLow operator and instance following the instruction from [here](https://ai-on-openshift.io/tools-and-applications/mlflow/mlflow/#pre-requisites)
* Install Kuberay operator using the following command:
  * ` oc create -k "github.com/ray-project/kuberay/ray-operator/config/default?ref=v0.5.0&timeout=90s"`
  * After the installation create a new namespace for a Ray cluster. If using the command line tool, create it as `oc new-project ray-cluster`
  * A cluster instance configuration is provided in the ![kuberay-cluster-example](kuberay-cluster-example) folder. This will create a cluster of 10 workers. At full scale, this cluster requires 20 CPU and 40GB of RAM from the RHOCP cluster. Make sure you have sufficient compute configured in your OCP cluster before creating the cluster from that sample file, or adjust the resource definition accordingly. To create a cluster instance using the provided sample, execute `oc apply -f kuberay-cluster-example/ray-cluster.complete-py39-tf2_11_1-4Gi.yaml `.
* Install Red Hat OpenShift AI (formerly known as Red Hat OpenShift Data Science) operator and create an instance. This operator will create several namespaces. The route to the UI, the RHOAI dashboard, is available under the `rhods-applications` namespace.

## ETSAD Syntetic Data Creation
TBD

## Data generation and ML experimentation environment setup
The Red Hat OpenShift AI operator (formerly known Red Hat OpenShift Data Science) packages several AI/ML tools. One of them is Jupyter labs. In order to access it, we need to create a project inside th RHOAI console. Let's name the new project `etsad`. 
TBD.